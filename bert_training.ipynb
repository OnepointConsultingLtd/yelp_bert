{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import seaborn as sns\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/yelp/')\n",
    "assert path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_simplified_reviews.pkl      yelp_academic_dataset_tip.json\n",
      "Dataset_User_Agreement.pdf\t     yelp_academic_dataset_user.json\n",
      "model_save\t\t\t     yelp_dataset.tar\n",
      "output_dir_0\t\t\t     yelp_reviews_simple_1000000.json\n",
      "output_dir_1\t\t\t     yelp_reviews_simple_2000000.json\n",
      "output_dir_2\t\t\t     yelp_reviews_simple_200000.json\n",
      "yelp_academic_dataset_business.json  yelp_reviews_simple_400000.json\n",
      "yelp_academic_dataset_checkin.json   yelp_reviews_simple.json\n",
      "yelp_academic_dataset_review.json\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_simplified_reviews = pd.read_pickle(path/'balanced_simplified_reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>This actually used to be one of my favorite ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Decent food. Fishermen lobster or even congee ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Pros: Fun atmosphere, great for people watchin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>I love bookstores, and I love to spend some ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>I passed Five Guys, In-N-Out, Carl's Jr, and S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999994</th>\n",
       "      <td>Read the hype on Yelp and I just don't get it....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>I'm so pleased to have stumbled across this ut...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>I loved my waffle!!  It was amazing.  Yes it i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>Best Long Island Iced Teas anywhere. I love co...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>I love the mirrors on all the pillars. It give...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394411 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  stars\n",
       "31      This actually used to be one of my favorite ho...      1\n",
       "62      Decent food. Fishermen lobster or even congee ...      1\n",
       "77      Pros: Fun atmosphere, great for people watchin...      1\n",
       "85      I love bookstores, and I love to spend some ti...      1\n",
       "86      I passed Five Guys, In-N-Out, Carl's Jr, and S...      1\n",
       "...                                                   ...    ...\n",
       "999994  Read the hype on Yelp and I just don't get it....      1\n",
       "999995  I'm so pleased to have stumbled across this ut...      4\n",
       "999996  I loved my waffle!!  It was amazing.  Yes it i...      4\n",
       "999997  Best Long Island Iced Teas anywhere. I love co...      3\n",
       "999998  I love the mirrors on all the pillars. It give...      3\n",
       "\n",
       "[394411 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_simplified_reviews['stars'] = balanced_simplified_reviews['stars'] - 1\n",
    "balanced_simplified_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare tokenizer and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(balanced_simplified_reviews['stars'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(df):\n",
    "    df['text_len'] = df['text'].apply(lambda t : len(tokenizer.encode(t, max_length=config.MAX_LENGTH)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "balanced_simplified_reviews = parallelize_dataframe(balanced_simplified_reviews, count_tokens, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the distribution of the length of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(balanced_simplified_reviews['text_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews, self.targets,  self.tokenizer, self.max_len = reviews.to_numpy(), targets.to_numpy(), tokenizer, max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        review = self.reviews[item]\n",
    "        tokens = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'review': review,\n",
    "            'input_ids': tokens['input_ids'].flatten(),\n",
    "            'attention_mask': tokens['attention_mask'].flatten(),\n",
    "            'target': torch.tensor(self.targets[item]).long()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(balanced_simplified_reviews, test_size=0.1, random_state=RANDOM_SEED, stratify=balanced_simplified_reviews.stars.values)\n",
    "valid_df, test_df = train_test_split(test_df, test_size=0.5, random_state=RANDOM_SEED, stratify=test_df.stars.values)\n",
    "train_df.shape, test_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the distribution is even. We used `stratify` so it should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(valid_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_length, batch_size):\n",
    "    ds = YelpDataset(df['text'], df['stars'], tokenizer, max_length)\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=multiprocessing.cpu_count() - 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4\n",
    "\n",
    "train_dl = create_data_loader(train_df, tokenizer, config.MAX_LENGTH, BATCH_SIZE)\n",
    "test_dl = create_data_loader(test_df, tokenizer, config.MAX_LENGTH, BATCH_SIZE)\n",
    "valid_dl = create_data_loader(valid_df, tokenizer, config.MAX_LENGTH, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_record = next(iter(train_dl))\n",
    "sample_record['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_record['attention_mask'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(config.PRE_TRAINED_MODEL_NAME, num_labels = NUM_CLASSES, output_attentions = False, output_hidden_states = False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-3},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([p for n, p in param_optimizer if not any(nd in n for nd in no_decay)]), len([p for n, p in param_optimizer if any(nd in n for nd in no_decay)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamW Adam algorithm with weight decay fix\n",
    "optimizer = AdamW(optimizer_parameters, \n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "total_steps = len(train_dl) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "def save_model(model, tokenizer, output_dir = path/'model_save'):\n",
    "\n",
    "    # Create output directory if needed\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    else:\n",
    "        shutil.rmtree(output_dir)\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(f\"Saving model to {output_dir}\")\n",
    "\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    torch.save(model, output_dir/'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_batch_data(batch):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    input_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['target'].to(device)\n",
    "    return input_ids, input_mask, labels\n",
    "\n",
    "def eval_fn():\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    \n",
    "    # Evaluate data for one epoch\n",
    "    for batch in tqdm(valid_dl, total=len(valid_dl)):\n",
    "        input_ids, input_mask, labels = grab_batch_data(batch)\n",
    "        with torch.no_grad():        \n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            (loss, logits) = model(input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=input_mask,\n",
    "                                   labels=labels)\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            \n",
    "    avg_val_accuracy = total_eval_accuracy / len(valid_dl)\n",
    "    avg_val_loss = total_eval_loss / len(valid_dl)\n",
    "    print(f\"  Accuracy: {avg_val_accuracy:.2f}\")\n",
    "    print(f\"  Validation Loss: {avg_val_loss:.2f}\")\n",
    "    return {\n",
    "        'Accuracy': avg_val_accuracy,\n",
    "        'Validation Loss': avg_val_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stats = []\n",
    "best_accuracy = 0\n",
    "for epoch in tqdm(range(0, EPOCHS), total=EPOCHS):\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in tqdm(enumerate(train_dl), total=len(train_dl)):\n",
    "        input_ids, input_mask, labels = grab_batch_data(batch)\n",
    "        model.zero_grad()  \n",
    "        loss, logits = model(input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=input_mask, \n",
    "                             labels=labels)\n",
    "        total_train_loss += loss.item()\n",
    "        if step % 2000 == 0:\n",
    "            print(f'{step}: Loss: {total_train_loss / (step + 1)}\\r')\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dl)\n",
    "    print(\"\")\n",
    "    print(f\"  Average training loss: {avg_train_loss}\")\n",
    "    stats_info = eval_fn()\n",
    "    stats_info['epoch'], stats_info['Average training loss'] = epoch, avg_train_loss\n",
    "    training_stats.append(stats_info)\n",
    "    save_model(model, tokenizer, output_dir=path/f'output_dir_{epoch}')\n",
    "    if stats_info['Accuracy'] > best_accuracy:\n",
    "        save_model(model, tokenizer, output_dir=path/f'output_dir_best')\n",
    "        best_accuracy = stats_info['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, input_mask, labels = grab_batch_data(next(iter(valid_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, logits = model(input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=input_mask, \n",
    "                             labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
